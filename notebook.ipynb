{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project, Machine Learning Fall 2021, John Harrington\n",
    "## Introduction and References\n",
    "\n",
    "For my project I have used the audio-only files of the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) dataset.\n",
    "The dataset includes 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent.\n",
    " The classes of emotion include calm, happy, sad, angry, fearful, surprise, and disgust.\n",
    " Each expression is produced at two levels of emotional intensity (normal and strong), with an additional neutral performance.\n",
    "\n",
    "The most accurate model I have been able to implement (in terms of testing accuracy) is a neural netowrk with two hidden layers, performs optimization with Adam, uses cross entropy to calculate loss, and uses ReLU as an activation function.  \n",
    "\n",
    "Extracted features include:\n",
    "\n",
    "https://librosa.org/doc/latest/feature.html\n",
    "\n",
    "1) Chroma_stft - Compute a chromagram from a waveform or power spectrogram. A spectrogram is a representation of frequency over time with the addition of amplitude as a third dimension, denoting the intensity or volume of the signal at a frequency and a time.\n",
    "\n",
    "2) MFCC - Mel-frequency cepstral coefficients (MFCCs). MFCCs are commonly derived as follows: First, take the Fourier transform of a signal, second map the powers of the spectrum obtained above onto the mel scale, using triangular overlapping windows or alternatively, cosine overlapping windows, third take the logs of the powers at each of the mel frequencies, fourth take the discrete cosine transform of the list of mel log powers, as if it were a signal, lastly the MFCCs are the amplitudes of the resulting spectrum.\n",
    "\n",
    "3) Mel Spectogram - Compute a mel-scaled spectrogram. Studies have shown that humans do not perceive frequencies on a linear scale. We are better at detecting differences in lower frequencies than higher frequencies. For example, we can easily tell the difference between 500 and 1000 Hz, but we will hardly be able to tell a difference between 10,000 and 10,500 Hz, even though the distance between the two pairs are the same. In 1937, Stevens, Volkmann, and Newmann proposed a unit of pitch such that equal distances in pitch sounded equally distant to the listener. This is called the mel scale. We perform a mathematical operation on frequencies to convert them to the mel scale\n",
    "\n",
    " Feature extraction is performed using the Python library\n",
    " 'Librosa' which is intended for music and audio analysis. Librosa\n",
    " will read each file as a 1D Numpy array (1D since I have converted\n",
    " all files to be mono channel audio, as opposed to stereo.\n",
    " I did this because almost all RAVDESS files were already in mono channel,\n",
    " and so it made most sense to convert the few stereo recordings to mono\n",
    " using the CLI tool 'ffmpeg.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import librosa\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import wavfile\n",
    "import sounddevice as sd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining our Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bef68fe67673>:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, data = wavfile.read(\"RAVDESS/Actor_01/03-01-01-01-01-01-01.wav\")\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"RAVDESS/Actor_01/03-01-01-01-01-01-01.wav\")\n",
    "sd.play(data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-1d84b2b58cac>:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, data = wavfile.read(\"RAVDESS/Actor_01/03-01-01-01-02-01-01.wav\")\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"RAVDESS/Actor_01/03-01-01-01-02-01-01.wav\")\n",
    "sd.play(data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-131e9cba8927>:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, data = wavfile.read(\"RAVDESS/Actor_17/03-01-01-01-01-01-17.wav\")\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"RAVDESS/Actor_17/03-01-01-01-01-01-17.wav\")\n",
    "sd.play(data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-017efb517d57>:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, data = wavfile.read(\"RAVDESS/Actor_16/03-01-01-01-01-01-16.wav\")\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"RAVDESS/Actor_16/03-01-01-01-01-01-16.wav\")\n",
    "sd.play(data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-7c45af82b690>:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, data = wavfile.read(\"RAVDESS/Actor_02/03-01-01-01-01-01-02.wav\")\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"RAVDESS/Actor_02/03-01-01-01-01-01-02.wav\")\n",
    "sd.play(data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step One: Prepare to extract features from audio samples\n",
    "def extract_feature(file):\n",
    "    with soundfile.SoundFile(file) as audio:\n",
    "        sample = audio.read(dtype=\"float32\")\n",
    "        sample_rate = audio.samplerate\n",
    "        stft = np.abs(librosa.stft(sample))\n",
    "        result = np.array([])\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=sample, sr = sample_rate, n_mfcc=40).T, axis = 0)\n",
    "        result = np.hstack((result,mfccs))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "        mel = np.mean(librosa.feature.melspectrogram(sample, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Classes:  dict_values(['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised'])\n"
     ]
    }
   ],
   "source": [
    "# Step Two: Audio files in the RAVDESS dataset are labeled by emotion, store these in a dict\n",
    "emotions = {\n",
    "    '01' : 'neutral',\n",
    "    '02' : 'calm',\n",
    "    '03' : 'happy',\n",
    "    '04' : 'sad',\n",
    "    '05' : 'angry',\n",
    "    '06' : 'fearful',\n",
    "    '07' : 'disgust',\n",
    "    '08' : 'surprised'\n",
    "}\n",
    "\n",
    "emotions_int = {\n",
    "    1 : 'neutral', \n",
    "    2 : 'calm', \n",
    "    3 : 'happy',\n",
    "    4 : 'sad', \n",
    "    5 : 'angry', \n",
    "    6 : 'fearful', \n",
    "    7 : 'disgust', \n",
    "    8: 'surprised'\n",
    "}\n",
    "\n",
    "emotion_list = list(emotions.values())\n",
    "print(len(emotions), \"Classes: \", emotions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440  Files Loaded\n",
      "180 Features Extracted\n"
     ]
    }
   ],
   "source": [
    "# Define a load function to use all RAVDESS data for training the model \n",
    "def load_training_data():\n",
    "    x, y = [], []\n",
    "    file_count = 0\n",
    "    for file in glob.glob(\"RAVDESS/Actor_*/*_mono.wav\"):\n",
    "        file_name = os.path.basename(file)\n",
    "        # print(file)\n",
    "        emotion = emotions[file_name.split(\"-\")[2]]\n",
    "        feature = extract_feature(file)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "        file_count += 1\n",
    "    print(file_count, \" Files Loaded\")\n",
    "    return train_test_split(np.array(x), y, train_size=0.5, random_state=None)\n",
    "\n",
    "x_train, x_test, y_train, y_test = load_training_data()\n",
    "print(x_train.shape[1], \"Features Extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from our audio samples below \n",
    "def load_test_data(file_name):\n",
    "    x = []\n",
    "    file_count = 0\n",
    "    for file in glob.glob(\"clips/\" + file_name):\n",
    "        file_name = os.path.basename(file)\n",
    "        # print(file)\n",
    "        feature = extract_feature(file)\n",
    "        x.append(feature)\n",
    "        file_count += 1\n",
    "    print(\"Emotion Classified As:\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Multi-Layer Perception Classifier (using PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 3.242, Training Accuracy: 14.167, Testing Accuracy: 13.611\n",
      "Epoch: 1000, Training Loss: 0.147, Training Accuracy: 82.086, Testing Accuracy: 12.639\n",
      "Epoch: 2000, Training Loss: 0.018, Training Accuracy: 90.826, Testing Accuracy: 12.083\n",
      "Epoch: 3000, Training Loss: 0.004, Training Accuracy: 93.883, Testing Accuracy: 12.222\n",
      "Epoch: 4000, Training Loss: 0.001, Training Accuracy: 95.412, Testing Accuracy: 12.361\n",
      "Epoch: 5000, Training Loss: 0.000, Training Accuracy: 96.329, Testing Accuracy: 12.639\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# Class to represent data for feeding into neural network \n",
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind]) # Get emotion as integer value, not String \n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512 # Optimal size for my machine\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU() # Activation function \n",
    "        self.linear1 = torch.nn.Linear(D_in, H) # Hidden layer \n",
    "        self.linear2 = torch.nn.Linear(H, D_out) # Output: 8 classes \n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.relu(x) \n",
    "        h_relu = self.linear1(first).clamp(min=0) # Clamp used to normalize data \n",
    "        second = self.relu(h_relu) \n",
    "        y_pred = self.linear2(second)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP(180, 90, 8) # Model receives 180 features, outputs most likely membership among 8 classes \n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe the high training accuracy and the low testing accuracy, this will be addressed but first let's see how our model classifies samples outside of the training dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Matrix (1999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Copper Top\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "calm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-627a2539dd8d>:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  test = torch.FloatTensor(load_test_data(\"coppertop_mono.wav\"))\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/coppertop_mono.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"coppertop_mono.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Just Doing My Job\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/doing_job_mono.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"doing_job_mono.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Two Lives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/garbage_mono.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"garbage_mono.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Mr. Rhinehart\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/mr_rhinehart_mono.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"mr_rhinehart_mono.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Perfect World\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/perfect_world_mono.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"perfect_world_mono.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Red Pill\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/red_pill_mono.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"red_pill_mono.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Remember Nothing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/rem_nothing_mono.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"rem_nothing_mono.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Why You're Here\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/neo_morph.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"neo_morph.wav\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### \"What You've Been Doing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "s, data = wavfile.read(\"clips/neo_trin.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"neo_trin.wav\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Chicken\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/chicken.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"chicken.wav\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying test samples from outside of 'The Matrix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bowling, The Big Lewbowski, 1998 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/bowling.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"bowling.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bill Clinton's Denial (1998) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "surprised\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/bill_1.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"bill_1.wav\"))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bill Clinton's Apology (1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "surprised\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/bill_2.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"bill_2.wav\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zed's Dead, Pulp Fiction (1994) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classified As:\n",
      "disgust\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read(\"clips/zeds_dead.wav\")\n",
    "sd.play(data, fs)\n",
    "\n",
    "test = torch.FloatTensor(load_test_data(\"zeds_dead.wav\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(test)\n",
    "    predicted_class = np.argmax(prediction).tolist()\n",
    "    print(emotions_int.get(predicted_class + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Striving for higher testing accuracy\n",
    "\n",
    "### Normalize input data before it meets the neural net:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.normalize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 2.086, Training Accuracy: 13.194, Testing Accuracy: 13.194\n",
      "Epoch: 1000, Training Loss: 1.680, Training Accuracy: 31.846, Testing Accuracy: 14.028\n",
      "Epoch: 2000, Training Loss: 1.572, Training Accuracy: 36.622, Testing Accuracy: 14.583\n",
      "Epoch: 3000, Training Loss: 1.424, Training Accuracy: 40.052, Testing Accuracy: 13.750\n",
      "Epoch: 4000, Training Loss: 1.320, Training Accuracy: 42.787, Testing Accuracy: 12.500\n",
      "Epoch: 5000, Training Loss: 1.187, Training Accuracy: 45.242, Testing Accuracy: 12.639\n"
     ]
    }
   ],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = nn.functional.normalize(torch.from_numpy(x_train)) # Normalize \n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.relu(x)\n",
    "        h_relu = self.linear1(first).clamp(min=0) \n",
    "        second = self.relu(h_relu)\n",
    "        y_pred = self.linear2(second)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP(180, 90, 8)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This hasn't improved our testing accuracy, but diminished training accuracy.\n",
    "\n",
    "###  Next, remove the normalization implemented above and instead use batch normalizaton:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 2.088, Training Accuracy: 7.361, Testing Accuracy: 12.778\n",
      "Epoch: 1000, Training Loss: 0.036, Training Accuracy: 89.963, Testing Accuracy: 12.500\n",
      "Epoch: 2000, Training Loss: 0.008, Training Accuracy: 94.971, Testing Accuracy: 12.778\n",
      "Epoch: 3000, Training Loss: 0.001, Training Accuracy: 96.645, Testing Accuracy: 12.361\n",
      "Epoch: 4000, Training Loss: 0.001, Training Accuracy: 97.481, Testing Accuracy: 12.222\n",
      "Epoch: 5000, Training Loss: 0.000, Training Accuracy: 97.984, Testing Accuracy: 12.361\n"
     ]
    }
   ],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(D_in) # Batch normalization \n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.batch_norm(x)\n",
    "        second = self.relu(first)\n",
    "        hidden = self.linear1(second).clamp(min=0)\n",
    "        h_relu = self.relu(hidden)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP(180, 90, 8)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This yields higher training accuracy, but testing accuracy is unaffected \n",
    "\n",
    "### Next, add dropout, which will zero out every Pth element on forward calls, preventing neuronal co-adaptation:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 2.050, Training Accuracy: 14.583, Testing Accuracy: 13.194\n",
      "Epoch: 1000, Training Loss: 0.315, Training Accuracy: 74.615, Testing Accuracy: 13.194\n",
      "Epoch: 2000, Training Loss: 0.215, Training Accuracy: 82.750, Testing Accuracy: 11.944\n",
      "Epoch: 3000, Training Loss: 0.187, Training Accuracy: 86.462, Testing Accuracy: 11.250\n",
      "Epoch: 4000, Training Loss: 0.194, Training Accuracy: 88.639, Testing Accuracy: 11.806\n",
      "Epoch: 5000, Training Loss: 0.227, Training Accuracy: 90.085, Testing Accuracy: 11.389\n"
     ]
    }
   ],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(D_in) # Batch normalization \n",
    "        self.dropout = torch.nn.Dropout(0.2)         # Dropout \n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.batch_norm(x)\n",
    "        dropped = self.dropout(first)\n",
    "        first_relu = self.relu(dropped)\n",
    "        hidden = self.linear1(first_relu).clamp(min=0)\n",
    "        h_relu = self.relu(hidden)\n",
    "        y_pred = self.linear2(hidden)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP(180, 90, 8)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This has not helped, and if anything has slightly worsened our train and test accuracy, it is safe to say that overfitting was not our problem. \n",
    "\n",
    "P was set to 0.2, which 'dropped' every fifth input element. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to original model and use a different optimizer (RMSProp): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 32.152, Training Accuracy: 13.056, Testing Accuracy: 13.194\n",
      "Epoch: 1000, Training Loss: 0.674, Training Accuracy: 69.598, Testing Accuracy: 13.750\n",
      "Epoch: 2000, Training Loss: 0.639, Training Accuracy: 76.933, Testing Accuracy: 13.750\n",
      "Epoch: 3000, Training Loss: 0.255, Training Accuracy: 80.574, Testing Accuracy: 15.000\n",
      "Epoch: 4000, Training Loss: 0.237, Training Accuracy: 82.884, Testing Accuracy: 13.611\n",
      "Epoch: 5000, Training Loss: 0.379, Training Accuracy: 84.573, Testing Accuracy: 12.778\n"
     ]
    }
   ],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.relu(x)\n",
    "        h_relu = self.linear1(first).clamp(min=0)\n",
    "        second = self.relu(h_relu)\n",
    "        y_pred = self.linear2(second)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP(180, 90, 8)\n",
    "optimizer = torch.optim.RMSprop(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RMSProp instead of Adam did yield slightly greater testing accuracy, but could this be because RMSProp uses a default learning rate of 1e-2 while Adam uses a default learning rate of 1e-3? \n",
    "\n",
    "### Next, use RMSProp again but set learning rate = 1e-1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 3421.895, Training Accuracy: 8.472, Testing Accuracy: 13.750\n",
      "Epoch: 1000, Training Loss: 2.069, Training Accuracy: 15.452, Testing Accuracy: 13.333\n",
      "Epoch: 2000, Training Loss: 2.051, Training Accuracy: 14.545, Testing Accuracy: 13.611\n",
      "Epoch: 3000, Training Loss: 2.059, Training Accuracy: 14.241, Testing Accuracy: 13.333\n",
      "Epoch: 4000, Training Loss: 2.090, Training Accuracy: 14.090, Testing Accuracy: 13.889\n",
      "Epoch: 5000, Training Loss: 2.044, Training Accuracy: 14.003, Testing Accuracy: 13.333\n"
     ]
    }
   ],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.relu(x)\n",
    "        h_relu = self.linear1(first).clamp(min=0)\n",
    "        second = self.relu(h_relu)\n",
    "        y_pred = self.linear2(second)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP(180, 90, 8)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not much improvement, next try SGD with learning rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 8.799, Training Accuracy: 12.778, Testing Accuracy: 13.472\n",
      "Epoch: 1000, Training Loss: 1.796, Training Accuracy: 25.619, Testing Accuracy: 13.611\n",
      "Epoch: 2000, Training Loss: 1.548, Training Accuracy: 29.010, Testing Accuracy: 12.361\n",
      "Epoch: 3000, Training Loss: 1.707, Training Accuracy: 30.761, Testing Accuracy: 15.139\n",
      "Epoch: 4000, Training Loss: 1.688, Training Accuracy: 31.987, Testing Accuracy: 14.722\n",
      "Epoch: 5000, Training Loss: 1.728, Training Accuracy: 32.775, Testing Accuracy: 14.028\n"
     ]
    }
   ],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.relu(x)\n",
    "        h_relu = self.linear1(first).clamp(min=0)\n",
    "        second = self.relu(h_relu)\n",
    "        y_pred = self.linear2(second)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP(180, 90, 8)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD was not helpful, next let's return to the orginal model and experment with adding hidden layers: \n",
    "\n",
    "### Our original model contained only one hidden layer: 180 features > 90 (HL) > 8 classes \n",
    "\n",
    "### Try 180 features > 90 > 45 > 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 2.217, Training Accuracy: 13.472, Testing Accuracy: 13.611\n",
      "Epoch: 1000, Training Loss: 0.015, Training Accuracy: 87.950, Testing Accuracy: 10.278\n",
      "Epoch: 2000, Training Loss: 0.001, Training Accuracy: 93.972, Testing Accuracy: 9.583\n",
      "Epoch: 3000, Training Loss: 0.000, Training Accuracy: 95.981, Testing Accuracy: 10.139\n",
      "Epoch: 4000, Training Loss: 0.000, Training Accuracy: 96.985, Testing Accuracy: 10.278\n",
      "Epoch: 5000, Training Loss: 0.000, Training Accuracy: 97.588, Testing Accuracy: 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(180, 90)\n",
    "        self.linear2 = torch.nn.Linear(90, 45)\n",
    "        self.linear3 = torch.nn.Linear(45, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.relu(x)\n",
    "        h_relu = self.linear1(first).clamp(min=0)\n",
    "        second_relu = self.relu(h_relu)\n",
    "        h_2 = self.linear2(second_relu)\n",
    "        third_relu = self.relu(h_2)\n",
    "        y_pred = self.linear3(third_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is trending in the right direction, so let's add more hidden layers: \n",
    "\n",
    "### 180 > 150 > 120 > 90 > 60 > 30 > 15 > 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 2.096, Training Accuracy: 13.333, Testing Accuracy: 13.611\n",
      "Epoch: 1000, Training Loss: 0.003, Training Accuracy: 87.215, Testing Accuracy: 13.056\n",
      "Epoch: 2000, Training Loss: 0.000, Training Accuracy: 93.604, Testing Accuracy: 12.500\n",
      "Epoch: 3000, Training Loss: 0.000, Training Accuracy: 95.736, Testing Accuracy: 11.944\n",
      "Epoch: 4000, Training Loss: 0.000, Training Accuracy: 96.801, Testing Accuracy: 11.806\n",
      "Epoch: 5000, Training Loss: 0.000, Training Accuracy: 97.441, Testing Accuracy: 11.667\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.x_train[ind]\n",
    "        y = emotion_list.index(y_train[ind])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_set = MakeDataset(x_train, y_train)\n",
    "test_set = MakeDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "class TwoLayerMLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(180, 150)\n",
    "        self.linear2 = torch.nn.Linear(150, 120)\n",
    "        self.linear3 = torch.nn.Linear(120, 90)\n",
    "        self.linear4 = torch.nn.Linear(90, 60)\n",
    "        self.linear5 = torch.nn.Linear(60, 30)\n",
    "        self.linear6 = torch.nn.Linear(30, 15)\n",
    "        self.linear7 = torch.nn.Linear(15, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.relu(x)\n",
    "        h_relu = self.linear1(first).clamp(min=0)\n",
    "        h_2 = self.linear2(h_relu)\n",
    "        rel_2 = self.relu(h_2)\n",
    "        h_3 = self.linear3(rel_2)\n",
    "        rel_3 = self.relu(h_3)\n",
    "        h_4 = self.linear4(rel_3)\n",
    "        rel_4 = self.relu(h_4)\n",
    "        h_5 = self.linear5(rel_4)\n",
    "        rel_5 = self.relu(h_5)\n",
    "        h_6 = self.linear6(h_5)\n",
    "        rel_6 = self.relu(h_6)\n",
    "        y_pred = self.linear7(rel_6)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = TwoLayerMLP()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5001\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        audio , label = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total_train += float(label.size(0))\n",
    "        correct_train += (sum(pred_indices == label)).item()\n",
    "        \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        audio , label = data\n",
    "        outputs = model(audio.float())\n",
    "        pred_values, pred_indices = torch.max(outputs.data,1)\n",
    "        total += float(label.size(0))\n",
    "        correct += (sum(pred_indices == label)).item()\n",
    "    train_accuracy = 100.*correct_train/total_train\n",
    "    test_accuracy = 100.*correct/total\n",
    "    if (epoch % 1000 == 0):\n",
    "        print(\"Epoch: %.0f, Training Loss: %.3f, Training Accuracy: %.3f, Testing Accuracy: %.3f\" % (epoch, loss.item(), train_accuracy, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This appears to have slightly increased training accuracy, and slightly worsened testing accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
